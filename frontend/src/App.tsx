import { useState, useRef, useEffect } from 'react'
import './App.css'

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// íƒ€ì… ì •ì˜
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface CompareResult {
  similarity: number
  interpretation: string
  model_used: string
  load_time: number
  inference_time: number
}

interface ModelResult {
  model_key: string
  model_path: string
  similarity: number
  interpretation: string
  load_time: number
  inference_time: number
  success: boolean
  error: string | null
}

interface MultiModelResult {
  results: ModelResult[]
  text1: string
  text2: string
}

interface MatrixResult {
  similarity_matrix: number[][]
  texts: string[]
  model_used: string
}

interface SearchResult {
  text: string
  similarity: number
  metadata: {
    doc_name: string
    doc_title?: string
    chunk_index: number
    total_chunks?: number
    chunk_method?: string
    article_num?: string
    article_type?: string
    section?: string
  }
  aiAnswer?: string
  aiLoading?: boolean
}

interface ClarificationOption {
  doc_name: string
  display_text: string
  score: number
}

interface RAGResponse {
  query: string
  answer?: string
  results?: SearchResult[]
  sources?: SearchResult[]
  needs_clarification?: boolean
  clarification_options?: ClarificationOption[]
}

interface DocumentInfo {
  doc_name: string
  doc_title?: string
  chunk_count: number
  chunk_method?: string
}

interface LLMModelsResponse {
  ollama: {
    server_running: boolean
    available_models: string[]
    models: Array<{ key: string; name: string; desc: string; vram: string; available: boolean }>
  }
  huggingface: {
    models: Array<{ key: string; name: string; desc: string }>
  }
}

// ì„ë² ë”© ëª¨ë¸ ìŠ¤í™ íƒ€ì… â† NEW
interface EmbeddingModelSpec {
  path: string
  name: string
  dim: number
  memory_mb: number
  lang: string
  desc: string
  compatible: boolean
  warning?: boolean
}

interface EmbeddingModelsResponse {
  all: EmbeddingModelSpec[]
  compatible: EmbeddingModelSpec[]
  incompatible: EmbeddingModelSpec[]
  filter_criteria: {
    max_dim: number
    max_memory_mb: number
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// í”„ë¦¬ì…‹ ëª¨ë¸ (í˜¸í™˜ì„± ì •ë³´ í¬í•¨) â† UPDATED
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const PRESET_MODELS = [
  { key: 'ko-sroberta', name: 'Ko-SROBERTA', desc: 'í•œêµ­ì–´ ì¶”ì²œ', dim: 768, mem: 440, compatible: true },
  { key: 'ko-sbert', name: 'Ko-SBERT', desc: 'í•œêµ­ì–´', dim: 768, mem: 440, compatible: true },
  { key: 'ko-simcse', name: 'Ko-SimCSE', desc: 'í•œêµ­ì–´', dim: 768, mem: 440, compatible: true },
  { key: 'qwen3-0.6b', name: 'Qwen3-0.6B', desc: 'ë‹¤êµ­ì–´ ê²½ëŸ‰', dim: 1024, mem: 600, compatible: true },
  { key: 'qwen3-4b', name: 'Qwen3-4B', desc: 'âš ï¸ dim/mem ì´ˆê³¼', dim: 2560, mem: 4000, compatible: false },
  { key: 'multilingual-minilm', name: 'MiniLM ë‹¤êµ­ì–´', desc: 'ê²½ëŸ‰', dim: 384, mem: 470, compatible: true },
  { key: 'multilingual-e5', name: 'E5 ë‹¤êµ­ì–´', desc: 'ê³ ì„±ëŠ¥', dim: 1024, mem: 1200, compatible: true },
  { key: 'bge-m3', name: 'BGE-M3', desc: 'ìµœì‹ ', dim: 1024, mem: 1300, compatible: true },
  { key: 'minilm', name: 'MiniLM', desc: 'ì˜ì–´ ê²½ëŸ‰', dim: 384, mem: 90, compatible: true },
  { key: 'mpnet', name: 'MPNet', desc: 'ì˜ì–´ ê³ ì„±ëŠ¥', dim: 768, mem: 420, compatible: true },
]

const OLLAMA_MODELS = [
  { key: 'qwen2.5:0.5b', name: 'Qwen2.5-0.5B', desc: 'ì´ˆê²½ëŸ‰ (1GB)' },
  { key: 'qwen2.5:1.5b', name: 'Qwen2.5-1.5B', desc: 'ê²½ëŸ‰ (2GB)' },
  { key: 'qwen2.5:3b', name: 'Qwen2.5-3B', desc: 'ì¶”ì²œ (3GB)' },
  { key: 'qwen2.5:7b', name: 'Qwen2.5-7B', desc: 'ê³ ì„±ëŠ¥ (5GB)' },
  { key: 'qwen3:4b', name: 'Qwen3-4B', desc: 'ìµœì‹  ì¶”ì²œ (4GB)' },
  { key: 'llama3.2:3b', name: 'Llama3.2-3B', desc: 'ê²½ëŸ‰ (3GB)' },
  { key: 'gemma2:2b', name: 'Gemma2-2B', desc: 'ê²½ëŸ‰ (2GB)' },
  { key: 'mistral:7b', name: 'Mistral-7B', desc: 'ì˜ì–´ íŠ¹í™” (5GB)' },
]

const HF_MODELS = [
  { key: 'Qwen/Qwen2.5-0.5B-Instruct', name: 'Qwen2.5-0.5B', desc: 'ì´ˆê²½ëŸ‰' },
  { key: 'Qwen/Qwen2.5-1.5B-Instruct', name: 'Qwen2.5-1.5B', desc: 'ê²½ëŸ‰' },
  { key: 'Qwen/Qwen2.5-3B-Instruct', name: 'Qwen2.5-3B', desc: 'VRAM 6GB+' },
  { key: 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', name: 'TinyLlama', desc: 'ì˜ì–´ íŠ¹í™”' },
]

// ì²­í‚¹ ë°©ì‹ ì •ì˜ â† NEW
const CHUNK_METHODS = [
  { key: 'article', name: 'ğŸ“œ ì¡°í•­ ë‹¨ìœ„', desc: 'SOP/ë²•ë¥  ê¶Œì¥', icon: 'ğŸ“œ' },
  { key: 'recursive', name: 'ğŸ”„ Recursive', desc: 'ë­ì²´ì¸ ìŠ¤íƒ€ì¼', icon: 'ğŸ”„' },
  { key: 'semantic', name: 'ğŸ§  Semantic', desc: 'ì˜ë¯¸ ê¸°ë°˜ (ëŠë¦¼)', icon: 'ğŸ§ ' },
  { key: 'sentence', name: 'ğŸ“ ë¬¸ì¥ ë‹¨ìœ„', desc: 'ë¹ ë¦„', icon: 'ğŸ“' },
  { key: 'paragraph', name: 'ğŸ“„ ë¬¸ë‹¨ ë‹¨ìœ„', desc: 'ì¤‘ê°„', icon: 'ğŸ“„' },
  { key: 'llm', name: 'ğŸ¤– LLM íŒŒì‹±', desc: 'ê°€ì¥ ì •êµ (ê°€ì¥ ëŠë¦¼)', icon: 'ğŸ¤–' },
]

const API_URL = 'http://localhost:8000'

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const getSimilarityColor = (score: number) => {
  if (score >= 0.7) return '#22c55e'
  if (score >= 0.5) return '#eab308'
  if (score >= 0.3) return '#f97316'
  return '#ef4444'
}

const getSimilarityLabel = (score: number) => {
  if (score >= 0.8) return 'ë§¤ìš° ë†’ìŒ'
  if (score >= 0.6) return 'ë†’ìŒ'
  if (score >= 0.4) return 'ë³´í†µ'
  if (score >= 0.2) return 'ë‚®ìŒ'
  return 'ë§¤ìš° ë‚®ìŒ'
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ë©”ì¸ ì»´í¬ë„ŒíŠ¸
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function App() {
  // í…ìŠ¤íŠ¸ ë¹„êµ
  const [text1, setText1] = useState('')
  const [text2, setText2] = useState('')
  const [selectedModel, setSelectedModel] = useState('ko-sroberta')
  const [result, setResult] = useState<CompareResult | null>(null)
  const [multiResult, setMultiResult] = useState<MultiModelResult | null>(null)
  const [selectedModels, setSelectedModels] = useState<string[]>(['ko-sroberta', 'qwen3-0.6b'])
  const [texts, setTexts] = useState<string[]>(['', '', ''])
  const [matrixResult, setMatrixResult] = useState<MatrixResult | null>(null)

  // RAG
  const [ragQuery, setRagQuery] = useState('')
  const [ragResult, setRagResult] = useState<RAGResponse | null>(null)
  const [documents, setDocuments] = useState<DocumentInfo[]>([])
  const [uploadStatus, setUploadStatus] = useState<string>('')
  const [ragModel, setRagModel] = useState('ko-sroberta')
  
  // LLM
  const [llmBackend, setLlmBackend] = useState<'ollama' | 'huggingface'>('ollama')
  const [llmModel, setLlmModel] = useState('qwen2.5:3b')
  const [ollamaStatus, setOllamaStatus] = useState<{ running: boolean; models: string[] }>({ running: false, models: [] })
  
  // ì²­í‚¹ â† UPDATED
  const [chunkMethod, setChunkMethod] = useState<string>('article')
  const [chunkSize, setChunkSize] = useState<number>(500)
  const [semanticThreshold, setSemanticThreshold] = useState<number>(0.5)  // NEW
  const [chunkLlmModel, setChunkLlmModel] = useState<string>('qwen2.5:3b')  // NEW (LLM íŒŒì‹±ìš©)
  
  // ë˜ë¬»ê¸°
  const [enableClarification, setEnableClarification] = useState(true)
  const [clarificationMessage, setClarificationMessage] = useState<string | null>(null)
  const [clarificationOptions, setClarificationOptions] = useState<ClarificationOption[]>([])
  
  // ì„ë² ë”© ëª¨ë¸ ì •ë³´ â† NEW
  const [showModelInfo, setShowModelInfo] = useState(false)
  const [embeddingModels, setEmbeddingModels] = useState<EmbeddingModelsResponse | null>(null)
  
  const fileInputRef = useRef<HTMLInputElement>(null)
  const [globalAnswer, setGlobalAnswer] = useState<string>('')
  const [globalAnswerLoading, setGlobalAnswerLoading] = useState(false)
  const [loading, setLoading] = useState(false)
  const [activeTab, setActiveTab] = useState<'single' | 'multi' | 'matrix' | 'rag'>('rag')

  useEffect(() => {
    checkOllamaStatus()
    fetchEmbeddingModels()
  }, [])

  const checkOllamaStatus = async () => {
    try {
      const response = await fetch(`${API_URL}/models/llm`)
      if (response.ok) {
        const data: LLMModelsResponse = await response.json()
        setOllamaStatus({
          running: data.ollama.server_running,
          models: data.ollama.available_models
        })
        if (!data.ollama.server_running) {
          setLlmBackend('huggingface')
          setLlmModel('Qwen/Qwen2.5-0.5B-Instruct')
        }
      }
    } catch {
      setOllamaStatus({ running: false, models: [] })
      setLlmBackend('huggingface')
    }
  }

  // ì„ë² ë”© ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° â† NEW
  const fetchEmbeddingModels = async () => {
    try {
      const response = await fetch(`${API_URL}/models/embedding`)
      if (response.ok) {
        const data: EmbeddingModelsResponse = await response.json()
        setEmbeddingModels(data)
      }
    } catch {
      console.error('ì„ë² ë”© ëª¨ë¸ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨')
    }
  }

  const handleCompare = async () => {
    if (!text1.trim() || !text2.trim()) return alert('ë‘ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.')
    
    // ëª¨ë¸ í˜¸í™˜ì„± ì²´í¬
    const model = PRESET_MODELS.find(m => m.key === selectedModel)
    if (model && !model.compatible) {
      if (!confirm(`âš ï¸ ${model.name}ì€ dim=${model.dim}, mem=${model.mem}MBë¡œ ê¶Œì¥ ë²”ìœ„(dimâ‰¤1024, memâ‰¤1300MB)ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ?`)) {
        return
      }
    }
    
    setLoading(true)
    setResult(null)
    try {
      const response = await fetch(`${API_URL}/compare`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text1, text2, model: selectedModel })
      })
      if (response.ok) setResult(await response.json())
    } catch { alert('ì„œë²„ ì—°ê²° ì‹¤íŒ¨') }
    finally { setLoading(false) }
  }

  const handleMultiCompare = async () => {
    if (!text1.trim() || !text2.trim()) return alert('ë‘ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.')
    if (selectedModels.length < 1) return alert('ìµœì†Œ 1ê°œ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.')
    setLoading(true)
    setMultiResult(null)
    try {
      const response = await fetch(`${API_URL}/compare/models`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text1, text2, models: selectedModels })
      })
      if (response.ok) setMultiResult(await response.json())
    } catch { alert('ì„œë²„ ì—°ê²° ì‹¤íŒ¨') }
    finally { setLoading(false) }
  }

  const handleMatrixCompare = async () => {
    const validTexts = texts.filter(t => t.trim())
    if (validTexts.length < 2) return alert('ìµœì†Œ 2ê°œ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
    setLoading(true)
    setMatrixResult(null)
    try {
      const response = await fetch(`${API_URL}/compare/matrix`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ texts: validTexts, model: selectedModel })
      })
      if (response.ok) setMatrixResult(await response.json())
    } catch { alert('ì„œë²„ ì—°ê²° ì‹¤íŒ¨') }
    finally { setLoading(false) }
  }

  const handleFileUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0]
    if (!file) return
    
    // ëª¨ë¸ í˜¸í™˜ì„± ì²´í¬
    const model = PRESET_MODELS.find(m => m.key === ragModel)
    if (model && !model.compatible) {
      if (!confirm(`âš ï¸ ${model.name}ì€ ê¶Œì¥ ë²”ìœ„ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ?`)) {
        return
      }
    }
    
    setLoading(true)
    setUploadStatus('ì—…ë¡œë“œ ì¤‘...')
    try {
      const formData = new FormData()
      formData.append('file', file)
      formData.append('collection', 'documents')
      formData.append('chunk_size', chunkSize.toString())
      formData.append('chunk_method', chunkMethod)
      formData.append('model', ragModel)
      formData.append('overlap', '50')
      
      // Semantic ë¶„í• ìš© threshold
      if (chunkMethod === 'semantic') {
        formData.append('semantic_threshold', semanticThreshold.toString())
      }
      
      // LLM íŒŒì‹±ìš© ëª¨ë¸ ì„¤ì •
      if (chunkMethod === 'llm') {
        formData.append('llm_model', chunkLlmModel)
        formData.append('llm_backend', llmBackend)
      }
      
      const response = await fetch(`${API_URL}/rag/upload`, { method: 'POST', body: formData })
      if (response.ok) {
        const data = await response.json()
        setUploadStatus(`âœ… ${data.filename} (${data.chunks_created}ê°œ ì¡°ê°, ${data.chunk_method})`)
        fetchDocuments()
      } else {
        const errorData = await response.json()
        setUploadStatus(`âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: ${errorData.detail || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`)
      }
    } catch { setUploadStatus('âŒ ì—…ë¡œë“œ ì‹¤íŒ¨') }
    finally { 
      setLoading(false)
      if (fileInputRef.current) fileInputRef.current.value = ''
    }
  }

  const fetchDocuments = async () => {
    try {
      const response = await fetch(`${API_URL}/rag/documents?collection=documents`)
      if (response.ok) {
        const data = await response.json()
        setDocuments(data.documents || [])
      }
    } catch { console.error('ë¬¸ì„œ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨') }
  }

  const handleRAGSearch = async () => {
    if (!ragQuery.trim()) return alert('ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.')
    setLoading(true)
    setRagResult(null)
    setGlobalAnswer('')
    setClarificationMessage(null)
    setClarificationOptions([])
    try {
      const response = await fetch(`${API_URL}/rag/search`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query: ragQuery, collection: 'documents', n_results: 5, model: ragModel })
      })
      if (response.ok) setRagResult(await response.json())
    } catch { alert('ê²€ìƒ‰ ì‹¤íŒ¨') }
    finally { setLoading(false) }
  }

  const handleAIAnswer = async (filterDoc?: string) => {
    if (!ragQuery.trim()) return
    setGlobalAnswerLoading(true)
    setGlobalAnswer('')
    setClarificationMessage(null)
    
    try {
      const response = await fetch(`${API_URL}/rag/ask`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query: ragQuery,
          collection: 'documents',
          n_results: 5,
          embedding_model: ragModel,
          llm_model: llmModel,
          llm_backend: llmBackend,
          check_clarification: enableClarification && !filterDoc,
          filter_doc: filterDoc || null
        })
      })
      if (response.ok) {
        const data: RAGResponse = await response.json()
        
        if (data.needs_clarification && data.clarification_options) {
          setClarificationMessage(data.answer || '')
          setClarificationOptions(data.clarification_options)
          setGlobalAnswer('')
        } else {
          setGlobalAnswer(data.answer || 'ë‹µë³€ ìƒì„± ì‹¤íŒ¨')
          setClarificationMessage(null)
          setClarificationOptions([])
        }
        
        if (data.sources) {
          setRagResult(prev => prev ? { ...prev, results: data.sources } : { query: ragQuery, results: data.sources })
        }
      }
    } catch { setGlobalAnswer('ì˜¤ë¥˜ ë°œìƒ') }
    finally { setGlobalAnswerLoading(false) }
  }

  const handleSelectDocument = (docName: string) => {
    setClarificationMessage(null)
    setClarificationOptions([])
    handleAIAnswer(docName)
  }

  const handleChunkAIAnswer = async (index: number, chunkText: string) => {
    if (!ragResult?.results) return
    const updatedResults = [...ragResult.results]
    updatedResults[index] = { ...updatedResults[index], aiLoading: true }
    setRagResult({ ...ragResult, results: updatedResults })

    try {
      const response = await fetch(`${API_URL}/rag/ask-chunk`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query: ragQuery, chunk_text: chunkText, llm_model: llmModel, llm_backend: llmBackend })
      })
      const data = await response.json()
      const newResults = [...(ragResult.results || [])]
      newResults[index] = { ...newResults[index], aiAnswer: data.answer || 'ë‹µë³€ ì‹¤íŒ¨', aiLoading: false }
      setRagResult({ ...ragResult, results: newResults })
    } catch {
      const newResults = [...(ragResult.results || [])]
      newResults[index] = { ...newResults[index], aiAnswer: 'ì˜¤ë¥˜ ë°œìƒ', aiLoading: false }
      setRagResult({ ...ragResult, results: newResults })
    }
  }

  const handleDeleteDocument = async (docName: string) => {
    if (!confirm(`"${docName}" ì‚­ì œ?`)) return
    try {
      const response = await fetch(`${API_URL}/rag/document`, {
        method: 'DELETE',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ doc_name: docName, collection: 'documents' })
      })
      if (response.ok) {
        fetchDocuments()
        setUploadStatus(`ğŸ—‘ï¸ ${docName} ì‚­ì œë¨`)
      }
    } catch { alert('ì‚­ì œ ì‹¤íŒ¨') }
  }

  const handleTabChange = (tab: 'single' | 'multi' | 'matrix' | 'rag') => {
    setActiveTab(tab)
    if (tab === 'rag') fetchDocuments()
  }

  const getArticleInfo = (metadata: SearchResult['metadata']) => {
    const parts = []
    if (metadata.article_type === 'article' && metadata.article_num) parts.push(`ì œ${metadata.article_num}ì¡°`)
    else if (metadata.article_type === 'chapter' && metadata.article_num) parts.push(`ì œ${metadata.article_num}ì¥`)
    else if (metadata.article_num) parts.push(`${metadata.article_num}`)
    if (metadata.section) parts.push(metadata.section)
    return parts.join(' / ')
  }

  // ëª¨ë¸ ì„ íƒ ë Œë”ë§ (í˜¸í™˜ì„± í‘œì‹œ í¬í•¨) â† NEW
  const renderModelSelect = (value: string, onChange: (v: string) => void, showWarning: boolean = true) => (
    <select value={value} onChange={(e) => onChange(e.target.value)}>
      {PRESET_MODELS.map(m => (
        <option key={m.key} value={m.key} style={{ color: m.compatible ? 'inherit' : '#f97316' }}>
          {m.compatible ? '' : 'âš ï¸ '}{m.name} {showWarning && `(${m.dim}d, ${m.mem}MB)`}
        </option>
      ))}
    </select>
  )

  return (
    <div className="app">
      <header className="header">
        <h1 className="title">ğŸ” í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ + RAG v5.0</h1>
        <p className="subtitle">í™•ì¥ ì²­í‚¹ (Recursive/Semantic/LLM) + ëª¨ë¸ í•„í„°ë§ + Ollama ì§€ì›</p>
      </header>

      <div className="tabs">
        {(['single', 'multi', 'matrix', 'rag'] as const).map(tab => (
          <button key={tab} className={`tab ${activeTab === tab ? 'active' : ''}`} onClick={() => handleTabChange(tab)}>
            {tab === 'single' && 'ë‹¨ì¼ ë¹„êµ'}
            {tab === 'multi' && 'ëª¨ë¸ ë¹„êµ'}
            {tab === 'matrix' && 'ë§¤íŠ¸ë¦­ìŠ¤'}
            {tab === 'rag' && 'ğŸ“„ RAG'}
          </button>
        ))}
      </div>

      <main className="main">
        {activeTab === 'single' && (
          <>
            <div className="input-section">
              <div className="text-input">
                <label>í…ìŠ¤íŠ¸ 1</label>
                <textarea value={text1} onChange={(e) => setText1(e.target.value)} placeholder="ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸..." rows={5} />
              </div>
              <div className="text-input">
                <label>í…ìŠ¤íŠ¸ 2</label>
                <textarea value={text2} onChange={(e) => setText2(e.target.value)} placeholder="ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸..." rows={5} />
              </div>
            </div>
            <div className="model-select">
              <label>ëª¨ë¸ <button className="info-btn" onClick={() => setShowModelInfo(!showModelInfo)}>â„¹ï¸</button></label>
              {renderModelSelect(selectedModel, setSelectedModel)}
            </div>
            
            {/* ëª¨ë¸ ì •ë³´ íŒì—… */}
            {showModelInfo && embeddingModels && (
              <div className="model-info-popup">
                <div className="popup-header">
                  <h4>ğŸ“Š ì„ë² ë”© ëª¨ë¸ í•„í„° (dimâ‰¤{embeddingModels.filter_criteria.max_dim}, memâ‰¤{embeddingModels.filter_criteria.max_memory_mb}MB)</h4>
                  <button onClick={() => setShowModelInfo(false)}>Ã—</button>
                </div>
                <div className="model-lists">
                  <div className="compatible-list">
                    <h5>âœ… í˜¸í™˜ ({embeddingModels.compatible.length})</h5>
                    {embeddingModels.compatible.map(m => (
                      <div key={m.path} className="model-item">
                        <span>{m.name}</span>
                        <span className="model-spec">{m.dim}d / {m.memory_mb}MB</span>
                      </div>
                    ))}
                  </div>
                  <div className="incompatible-list">
                    <h5>âŒ ë¹„í˜¸í™˜ ({embeddingModels.incompatible.length})</h5>
                    {embeddingModels.incompatible.map(m => (
                      <div key={m.path} className="model-item warning">
                        <span>{m.name}</span>
                        <span className="model-spec">{m.dim}d / {m.memory_mb}MB</span>
                      </div>
                    ))}
                  </div>
                </div>
              </div>
            )}
            
            <button className="primary-btn" onClick={handleCompare} disabled={loading}>
              {loading ? 'ë¶„ì„ ì¤‘...' : 'ë¹„êµí•˜ê¸°'}
            </button>
            {result && (
              <div className="result-box">
                <div className="score-big" style={{ color: getSimilarityColor(result.similarity) }}>
                  {(result.similarity * 100).toFixed(1)}%
                </div>
                <div className="score-label">{result.interpretation}</div>
                <div className="score-bar">
                  <div className="score-fill" style={{ width: `${result.similarity * 100}%`, backgroundColor: getSimilarityColor(result.similarity) }} />
                </div>
              </div>
            )}
          </>
        )}

        {activeTab === 'multi' && (
          <>
            <div className="input-section">
              <div className="text-input">
                <label>í…ìŠ¤íŠ¸ 1</label>
                <textarea value={text1} onChange={(e) => setText1(e.target.value)} placeholder="ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸..." rows={4} />
              </div>
              <div className="text-input">
                <label>í…ìŠ¤íŠ¸ 2</label>
                <textarea value={text2} onChange={(e) => setText2(e.target.value)} placeholder="ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸..." rows={4} />
              </div>
            </div>
            <div className="model-grid">
              {PRESET_MODELS.map(m => (
                <label key={m.key} className={`model-chip ${selectedModels.includes(m.key) ? 'selected' : ''} ${!m.compatible ? 'incompatible' : ''}`} title={`${m.dim}d, ${m.mem}MB${!m.compatible ? ' (âš ï¸ ê¶Œì¥ ì´ˆê³¼)' : ''}`}>
                  <input type="checkbox" checked={selectedModels.includes(m.key)} onChange={() => setSelectedModels(prev => prev.includes(m.key) ? prev.filter(k => k !== m.key) : [...prev, m.key])} />
                  {!m.compatible && 'âš ï¸ '}{m.name}
                </label>
              ))}
            </div>
            <button className="primary-btn" onClick={handleMultiCompare} disabled={loading}>
              {loading ? 'ë¹„êµ ì¤‘...' : `${selectedModels.length}ê°œ ëª¨ë¸ë¡œ ë¹„êµ`}
            </button>
            {multiResult && (
              <div className="results-list">
                {multiResult.results.map((r, i) => (
                  <div key={i} className="result-row">
                    <span className="result-name">{r.model_key}</span>
                    <span className="result-score" style={{ color: getSimilarityColor(r.similarity) }}>{(r.similarity * 100).toFixed(1)}%</span>
                  </div>
                ))}
              </div>
            )}
          </>
        )}

        {activeTab === 'matrix' && (
          <>
            <div className="matrix-inputs">
              {texts.map((text, i) => (
                <div key={i} className="matrix-row">
                  <span className="row-num">{i + 1}</span>
                  <textarea value={text} onChange={(e) => { const newTexts = [...texts]; newTexts[i] = e.target.value; setTexts(newTexts) }} placeholder={`í…ìŠ¤íŠ¸ ${i + 1}`} rows={2} />
                  {texts.length > 2 && <button className="remove-btn" onClick={() => setTexts(texts.filter((_, j) => j !== i))}>Ã—</button>}
                </div>
              ))}
              {texts.length < 10 && <button className="add-btn" onClick={() => setTexts([...texts, ''])}>+ ì¶”ê°€</button>}
            </div>
            <button className="primary-btn" onClick={handleMatrixCompare} disabled={loading}>{loading ? 'ê³„ì‚° ì¤‘...' : 'ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±'}</button>
            {matrixResult && (
              <div className="matrix-table-wrap">
                <table className="matrix-table">
                  <thead><tr><th></th>{matrixResult.texts.map((_, i) => <th key={i}>{i + 1}</th>)}</tr></thead>
                  <tbody>
                    {matrixResult.similarity_matrix.map((row, i) => (
                      <tr key={i}>
                        <td className="row-head">{i + 1}</td>
                        {row.map((score, j) => <td key={j} style={{ backgroundColor: i === j ? '#333' : `${getSimilarityColor(score)}33`, color: getSimilarityColor(score) }}>{(score * 100).toFixed(0)}%</td>)}
                      </tr>
                    ))}
                  </tbody>
                </table>
              </div>
            )}
          </>
        )}

        {activeTab === 'rag' && (
          <>
            <div className="ollama-status">
              {ollamaStatus.running ? (
                <span className="status-ok">âœ… Ollama ì‹¤í–‰ ì¤‘ ({ollamaStatus.models.length}ê°œ ëª¨ë¸)</span>
              ) : (
                <span className="status-warn">âš ï¸ Ollama ë¯¸ì‹¤í–‰ - HuggingFace ì‚¬ìš©</span>
              )}
              <button className="refresh-btn" onClick={checkOllamaStatus}>ğŸ”„</button>
            </div>

            <div className="settings-row">
              <div className="setting">
                <label>ğŸ” ê²€ìƒ‰ ëª¨ë¸</label>
                {renderModelSelect(ragModel, setRagModel, false)}
              </div>
              <div className="setting">
                <label>ğŸ¤– LLM ë°±ì—”ë“œ</label>
                <select value={llmBackend} onChange={(e) => {
                  const backend = e.target.value as 'ollama' | 'huggingface'
                  setLlmBackend(backend)
                  setLlmModel(backend === 'ollama' ? 'qwen2.5:3b' : 'Qwen/Qwen2.5-0.5B-Instruct')
                }}>
                  <option value="ollama" disabled={!ollamaStatus.running}>Ollama (ë¡œì»¬)</option>
                  <option value="huggingface">HuggingFace</option>
                </select>
              </div>
              <div className="setting">
                <label>ğŸ’¬ ë‹µë³€ ëª¨ë¸</label>
                <select value={llmModel} onChange={(e) => setLlmModel(e.target.value)}>
                  {llmBackend === 'ollama' ? OLLAMA_MODELS.map(m => <option key={m.key} value={m.key}>{m.name} - {m.desc}</option>) : HF_MODELS.map(m => <option key={m.key} value={m.key}>{m.name} - {m.desc}</option>)}
                </select>
              </div>
            </div>

            {/* ì²­í‚¹ ì„¤ì • - í™•ì¥ë¨ â† UPDATED */}
            <div className="chunk-settings">
              <label className="chunk-label">ğŸ“¦ ì²­í‚¹ ë°©ì‹</label>
              <div className="chunk-method-grid">
                {CHUNK_METHODS.map(m => (
                  <button 
                    key={m.key} 
                    className={`chunk-btn ${chunkMethod === m.key ? 'active' : ''}`} 
                    onClick={() => setChunkMethod(m.key)}
                    title={m.desc}
                  >
                    <span className="chunk-icon">{m.icon}</span>
                    <span className="chunk-name">{m.name.replace(/^[^\s]+\s/, '')}</span>
                  </button>
                ))}
              </div>
              
              <div className="chunk-size">
                <span>ìµœëŒ€ ì¡°ê° í¬ê¸°: {chunkSize}ì</span>
                <input type="range" min="200" max="2000" step="100" value={chunkSize} onChange={(e) => setChunkSize(Number(e.target.value))} />
              </div>
              
              {/* Semantic ë¶„í•  ì˜µì…˜ â† NEW */}
              {chunkMethod === 'semantic' && (
                <div className="semantic-options">
                  <span>ğŸ§  ìœ ì‚¬ë„ ì„ê³„ê°’: {semanticThreshold.toFixed(2)}</span>
                  <input 
                    type="range" 
                    min="0.3" 
                    max="0.8" 
                    step="0.05" 
                    value={semanticThreshold} 
                    onChange={(e) => setSemanticThreshold(Number(e.target.value))} 
                  />
                  <span className="hint">ë‚®ì„ìˆ˜ë¡ ë” ì‘ê²Œ ë¶„í• </span>
                </div>
              )}
              
              {/* LLM íŒŒì‹± ì˜µì…˜ â† NEW */}
              {chunkMethod === 'llm' && (
                <div className="llm-chunk-options">
                  <span>ğŸ¤– íŒŒì‹±ìš© LLM:</span>
                  <select value={chunkLlmModel} onChange={(e) => setChunkLlmModel(e.target.value)}>
                    {llmBackend === 'ollama' 
                      ? OLLAMA_MODELS.map(m => <option key={m.key} value={m.key}>{m.name}</option>) 
                      : HF_MODELS.map(m => <option key={m.key} value={m.key}>{m.name}</option>)
                    }
                  </select>
                  <span className="hint">âš ï¸ ê°€ì¥ ëŠë¦¬ì§€ë§Œ ê°€ì¥ ì •í™•</span>
                </div>
              )}
            </div>

            <div className="clarification-toggle">
              <label>
                <input type="checkbox" checked={enableClarification} onChange={(e) => setEnableClarification(e.target.checked)} />
                ğŸ¤” ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ê²°ê³¼ ì‹œ ë˜ë¬»ê¸° (ì—ì´ì „íŠ¸ ëª¨ë“œ)
              </label>
            </div>

            <div className="upload-section">
              <label>ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ (PDF, DOCX, TXT)</label>
              <input ref={fileInputRef} type="file" accept=".pdf,.docx,.doc,.txt,.md,.html" onChange={handleFileUpload} disabled={loading} />
              {uploadStatus && <p className="status">{uploadStatus}</p>}
            </div>

            {documents.length > 0 && (
              <div className="doc-list">
                <label>ğŸ“š ì—…ë¡œë“œëœ ë¬¸ì„œ</label>
                {documents.map((doc, i) => (
                  <div key={i} className="doc-item">
                    <div>
                      <strong>{doc.doc_name}</strong>
                      <span className="doc-meta">{doc.chunk_count}ê°œ ì¡°ê°{doc.chunk_method && ` â€¢ ${doc.chunk_method}`}</span>
                    </div>
                    <button onClick={() => handleDeleteDocument(doc.doc_name)}>ğŸ—‘ï¸</button>
                  </div>
                ))}
              </div>
            )}

            <div className="query-section">
              <label>ğŸ’¬ ì§ˆë¬¸</label>
              <textarea value={ragQuery} onChange={(e) => setRagQuery(e.target.value)} placeholder="ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”... (ì˜ˆ: ì† ì”»ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”)" rows={3} />
              <div className="query-btns">
                <button className="search-btn" onClick={handleRAGSearch} disabled={loading || documents.length === 0}>ğŸ” ê²€ìƒ‰ë§Œ</button>
                <button className="ai-btn" onClick={async () => { await handleRAGSearch(); await handleAIAnswer() }} disabled={loading || globalAnswerLoading || documents.length === 0}>âœ¨ ê²€ìƒ‰ + AI ë‹µë³€</button>
              </div>
            </div>

            {clarificationMessage && clarificationOptions.length > 0 && (
              <div className="clarification-box">
                <div className="clarification-header">
                  <span className="agent-icon">ğŸ¤”</span>
                  <h3>í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤</h3>
                </div>
                <p className="clarification-msg">{clarificationMessage}</p>
                
                <div className="clarification-options">
                  {clarificationOptions.map((option, i) => (
                    <button 
                      key={i} 
                      className="option-btn" 
                      onClick={() => handleSelectDocument(option.doc_name)}
                      title={`ì •í™•ë„: ${(option.score * 100).toFixed(1)}%`}
                    >
                      <span className="doc-icon">ğŸ“„</span>
                      <span className="option-text">{option.display_text}</span>
                      <span className="option-score">{(option.score * 100).toFixed(0)}%</span>
                    </button>
                  ))}
                  
                  <button 
                    className="option-btn all" 
                    onClick={() => { 
                      setClarificationMessage(null); 
                      setClarificationOptions([]); 
                      setEnableClarification(false); 
                      handleAIAnswer(); 
                    }}
                  >
                    <span className="doc-icon">ğŸ“š</span>
                    <span className="option-text">ì „ì²´ ë¬¸ì„œ ë‚´ìš© ìš”ì•½í•˜ê¸°</span>
                  </button>
                </div>
              </div>
            )}

            {(globalAnswerLoading || globalAnswer) && !clarificationMessage && (
              <div className="global-answer">
                <h3>ğŸ¤– AI ì¢…í•© ë‹µë³€</h3>
                {globalAnswerLoading ? <div className="loading-answer"><span className="spinner"></span>ë‹µë³€ ìƒì„± ì¤‘... ({llmBackend === 'ollama' ? 'Ollama' : 'HuggingFace'})</div> : <div className="answer-text">{globalAnswer}</div>}
              </div>
            )}

            {ragResult?.results && ragResult.results.length > 0 && (
              <div className="search-results">
                <h3>ğŸ“„ ê´€ë ¨ ë¬¸ì„œ ì¡°ê° ({ragResult.results.length}ê°œ)</h3>
                {ragResult.results.map((r, idx) => (
                  <div key={idx} className="result-card">
                    <div className="card-header">
                      <div className="source-info">
                        <span className="source-file">ğŸ“„ {r.metadata?.doc_name}</span>
                        {getArticleInfo(r.metadata) && <span className="article-info">ğŸ“Œ {getArticleInfo(r.metadata)}</span>}
                      </div>
                      <div className="relevance" style={{ color: getSimilarityColor(r.similarity) }}>
                        <span className="relevance-value">{getSimilarityLabel(r.similarity)}</span>
                        <span className="relevance-percent">{(r.similarity * 100).toFixed(0)}%</span>
                      </div>
                    </div>
                    <div className="card-content">{r.text}</div>
                    <button className="chunk-ai-btn" onClick={() => handleChunkAIAnswer(idx, r.text)} disabled={r.aiLoading}>{r.aiLoading ? 'ìƒì„± ì¤‘...' : 'ğŸ¤– ì´ ë‚´ìš©ìœ¼ë¡œ ë‹µë³€ ìƒì„±'}</button>
                    {r.aiAnswer && <div className="chunk-answer"><div className="chunk-answer-title">ğŸ’¡ AI ë‹µë³€</div><div className="chunk-answer-text">{r.aiAnswer}</div></div>}
                  </div>
                ))}
              </div>
            )}

            {ragResult && (!ragResult.results || ragResult.results.length === 0) && !loading && <div className="no-results">ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</div>}
          </>
        )}
      </main>

      <footer className="footer">v5.0 - í™•ì¥ ì²­í‚¹ (Recursive/Semantic/LLM) + ì„ë² ë”© ëª¨ë¸ í•„í„°ë§ (dimâ‰¤1024, memâ‰¤1300MB)</footer>
    </div>
  )
}

export default App